{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4632f07-743b-415b-bfef-31aaee51579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import pingouin as pg\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from matplotlib import ticker\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc66f97-d0ce-4305-be26-39a699c6b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf8388-3b52-4629-b36e-98e6b5a31bbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_stata('DatasetPsychometricsMalawi.dta')\n",
    "df = pd.read_stata('AlexMartinToCheckScores.dta')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a5123-0e41-4699-b0d4-a1adac839ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame()\n",
    "df_clean['id'] = df.index\n",
    "\n",
    "#confidence\n",
    "cols = ['sec3_q24', 'sec3_q25', 'sec3_q30', 'sec3_q31', 'sec3_32', 'sec3_q37']\n",
    "for col in cols:\n",
    "    df_clean[col] = np.nan\n",
    "    df_clean.loc[df[col] == 'Strongly disagree', col] = 0\n",
    "    df_clean.loc[df[col] == 'Somewhat disagree', col] = 1\n",
    "    df_clean.loc[df[col] == 'Somewhat agree', col] = 2\n",
    "    df_clean.loc[df[col] == 'Strongly agree', col] = 3\n",
    "\n",
    "#talks\n",
    "cols = ['sec5_q51', 'sec5_q53',    'sec5_q58'] #'sec5_q57',\n",
    "for col in cols:\n",
    "    df_clean[col] = np.nan\n",
    "    df_clean.loc[df[col] == 'No', col] = 0\n",
    "    df_clean.loc[df[col] == 3, col] = 3\n",
    "    df_clean.loc[df[col] == 'No one', col] = 3\n",
    "    df_clean.loc[df[col] == 'Yes, many people', col] = 0\n",
    "    df_clean.loc[df[col] == 'Yes, a few people', col] = 0\n",
    "    df_clean.loc[df[col] == 'Yes, one person', col] = 0\n",
    "\n",
    "#concerns\n",
    "cols = ['sec3_q33', 'sec3_q34', 'sec3_q35', 'sec3_q36']\n",
    "for col in cols:\n",
    "    df_clean[col] = np.nan\n",
    "    df_clean.loc[df[col] == 'Strongly disagree', col] = 3\n",
    "    df_clean.loc[df[col] == 'Somewhat disagree', col] = 2\n",
    "    df_clean.loc[df[col] == 'Somewhat agree', col] = 1\n",
    "    df_clean.loc[df[col] == 'Strongly agree', col] = 0\n",
    "\n",
    "#feels others\n",
    "cols = ['sec5_q56']\n",
    "for col in cols:\n",
    "    df_clean[col] = np.nan\n",
    "    df_clean.loc[df[col] == 'Strongly disagree', col] = 0\n",
    "    df_clean.loc[df[col] == 'Disagree', col] = 1\n",
    "    df_clean.loc[df[col] == 'Agree', col] = 2\n",
    "    df_clean.loc[df[col] == 'Strongly agree', col] = 3\n",
    "\n",
    "#outcome\n",
    "df_clean['anydoses'] = df['anydoses']\n",
    "df_clean = df_clean[~df_clean.anydoses.isna()].reset_index().copy()\n",
    "\n",
    "df_clean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ca2f1-ca66-41a1-8e0e-4fa26f4b248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051f74b-78b0-4ece-b160-7764ee5e87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data by question\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd07577c-56fa-459c-8612-e6d255f7a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many questions did each person skip?\n",
    "pd.DataFrame(df_clean.isna().sum(axis=1)).groupby(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c6c18-9711-4cc2-a45d-b023363032de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of observations with at least one missing question\n",
    "df_clean.id[df_clean.isna().sum(axis=1)>0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099aeeff-0030-43d1-8d25-60b054930ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "30/253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951f917-1ba2-4583-a539-27ff758098e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_clean.columns.drop('id'):\n",
    "    df_clean[col] = df_clean[col].astype('category')\n",
    "    \n",
    "df_clean[df_clean.columns.drop('id')].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff722cdb-970e-48ec-8c19-2789d7234472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a9981-b3ec-4155-873a-d8eba13f6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby('anydoses').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045e4e6-e642-4fe4-bc91-5579fe4736d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "\n",
    "for col in df_clean.columns.drop('id'):\n",
    "    df_clean[col] = df_clean[col].astype('category')\n",
    "\n",
    "num_datasets = 20\n",
    "\n",
    "kernel = mf.ImputationKernel(\n",
    "  df_clean[df_clean.columns.drop('id')],\n",
    "  num_datasets=num_datasets,\n",
    "  random_state=1991,\n",
    "  mean_match_candidates=0  # Skip mean matching\n",
    ")\n",
    "\n",
    "kernel.mice(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506be60-e1fd-4963-8138-e46ea6ddb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.complete_data(dataset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d263e9-909f-4c82-af2d-b75f9152685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average scores\n",
    "\n",
    "cols = ['motivationscore', \n",
    "       'confidence', 'sec3_q24', 'sec3_q25', 'sec3_q30', 'sec3_q31', 'sec3_32', 'sec3_q37', \n",
    "       'talks', 'sec5_q51', 'sec5_q53',        'sec5_q58', #'sec5_q57', \n",
    "       'concerns', 'sec3_q33', 'sec3_q34', 'sec3_q35', 'sec3_q36', \n",
    "       'feelsothers']\n",
    "\n",
    "coefs = pd.DataFrame([], columns = cols)\n",
    "errs = pd.DataFrame([], columns = cols)\n",
    "\n",
    "\n",
    "for d in range(num_datasets):\n",
    "    df_imputed = kernel.complete_data(dataset=d).copy()\n",
    "\n",
    "    for col in df_imputed.columns:\n",
    "        df_imputed[col] = df_imputed[col].astype('int')\n",
    "\n",
    "    df_imputed['confidence'] = df_imputed['sec3_q24'] + df_imputed['sec3_q25'] + df_imputed['sec3_q30'] + df_imputed['sec3_q31'] + df_imputed['sec3_32'] + df_imputed['sec3_q37']\n",
    "    df_imputed['talks'] = df_imputed['sec5_q51'] + df_imputed['sec5_q53'] +           df_imputed['sec5_q58'] # df_imputed['sec5_q57'] +\n",
    "    df_imputed['concerns'] = df_imputed['sec3_q33'] + df_imputed['sec3_q34'] + df_imputed['sec3_q35'] + df_imputed['sec3_q36']\n",
    "    df_imputed['feelsothers'] = df_imputed['sec5_q56']\n",
    "    df_imputed['motivationscore'] = df_imputed['confidence'] + df_imputed['talks'] + df_imputed['concerns'] + df_imputed['feelsothers']\n",
    "    \n",
    "    cs = []\n",
    "    stderrs = []\n",
    "    for col in cols:\n",
    "        \n",
    "        cs = cs + [df_imputed[col].mean()]\n",
    "        stderrs = stderrs + [df_imputed[col].sem()]\n",
    "    \n",
    "    coefs.loc[d] = cs\n",
    "    errs.loc[d] = stderrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb0fe9-aee4-43f3-ad47-178f2802d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(round(coefs.mean(), 2).astype(str) + ' ± ' + round((((errs.mean())**2 + ((1 + 1/num_datasets) * (num_datasets) / (num_datasets - 1) * errs.std())**2)**0.5)*1.96,2).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cf5aa-1c23-46d7-bd66-b22ecda9de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# odds ratios\n",
    "\n",
    "cols = ['motivationscore', \n",
    "       'confidence', 'sec3_q24', 'sec3_q25', 'sec3_q30', 'sec3_q31', 'sec3_32', 'sec3_q37', \n",
    "       'talks', 'sec5_q51', 'sec5_q53',       'sec5_q58', # 'sec5_q57',\n",
    "       'concerns', 'sec3_q33', 'sec3_q34', 'sec3_q35', 'sec3_q36', \n",
    "       'feelsothers']\n",
    "\n",
    "coefs = pd.DataFrame([], columns = cols)\n",
    "errs = pd.DataFrame([], columns = cols)\n",
    "\n",
    "\n",
    "for d in range(num_datasets):\n",
    "    df_imputed = kernel.complete_data(dataset=d).copy()\n",
    "\n",
    "    for col in df_imputed.columns:\n",
    "        df_imputed[col] = df_imputed[col].astype('int')\n",
    "    \n",
    "    df_imputed['const'] = 1\n",
    "    df_imputed['confidence'] = df_imputed['sec3_q24'] + df_imputed['sec3_q25'] + df_imputed['sec3_q30'] + df_imputed['sec3_q31'] + df_imputed['sec3_32'] + df_imputed['sec3_q37']\n",
    "    df_imputed['talks'] = df_imputed['sec5_q51'] + df_imputed['sec5_q53']          + df_imputed['sec5_q58'] # + df_imputed['sec5_q57']\n",
    "    df_imputed['concerns'] = df_imputed['sec3_q33'] + df_imputed['sec3_q34'] + df_imputed['sec3_q35'] + df_imputed['sec3_q36']\n",
    "    df_imputed['feelsothers'] = df_imputed['sec5_q56']\n",
    "    df_imputed['motivationscore'] = df_imputed['confidence'] + df_imputed['talks'] + df_imputed['concerns'] + df_imputed['feelsothers']\n",
    "\n",
    "    \n",
    "    cs = []\n",
    "    stderrs = []\n",
    "    for col in cols:\n",
    "\n",
    "        y = df_imputed['anydoses'] \n",
    "        X = df_imputed[['const', col]] \n",
    "    \n",
    "        model = sm.Logit(y, X)\n",
    "        res = model.fit(maxiter = 100)\n",
    "\n",
    "        vals = res.summary2().tables[1]\n",
    "        cs = cs + [vals['Coef.'].iloc[1]]\n",
    "        stderrs = stderrs + [vals['Std.Err.'].iloc[1]]\n",
    "    \n",
    "    coefs.loc[d] = cs\n",
    "    errs.loc[d] = stderrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f9ab83-2c7d-43c8-ab54-03dd88b40d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "coef_mi = coefs.mean()\n",
    "stderr_mi = (errs.mean()**2 + (1 + 1/num_datasets) * (num_datasets) / (num_datasets - 1) * errs.std()**2)**0.5\n",
    "df_ans= pd.DataFrame(np.round(np.exp(coef_mi),2).astype(str) + ' [' + np.round(np.exp(coef_mi - 1.96 * stderr_mi),2).astype(str) + ', ' + np.round(np.exp(coef_mi + 1.96 * stderr_mi),2).astype(str) + ']', columns = ['OR'])\n",
    "df_ans['p'] = np.round((1 - st.norm.cdf(np.abs(coef_mi/stderr_mi))) * 2,4)\n",
    "df_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7238b0-b2c5-4770-9545-32ab49a560ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1423393-04cc-4425-a6e7-2e02eb5b2232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e7ec4-2ce1-4bd7-bb2b-70a88969ef14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92603573-6e63-494f-ba34-5f714fc294d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kenya data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad984908-67b6-4c71-af08-856c0d9dc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00453b64-741a-4668-9e6e-cde7d4221c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('hpvaxdataset20230113_1347.dta')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe90bf8-86a7-4d09-903e-8d189973f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a6ed5-6d7f-45d5-a0e9-12b678857f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdac001-f1a7-4ace-80b7-7d0e98164e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'sec5_q64', 'sec5_q63', 'sec6_q73', 'sec6_q74', 'sec3_q33', 'sec5_q60', 'sec5_q62', 'Correct_A_q83'\n",
    "df.groupby('Correct_A_q83', dropna=False, observed=True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662991b3-0db3-4ad4-9c26-b725ead36940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame()\n",
    "df_clean['id'] = df.index\n",
    "df_clean['caseid'] = df.caseid\n",
    "\n",
    "#confidence\n",
    "cols = ['sec3_q28', 'sec3_q29', 'sec3_q36', 'sec3_q37', 'sec3_q38', 'sec3_q45']\n",
    "for col in cols:\n",
    "    df_clean[col] = np.nan\n",
    "    df_clean.loc[df[col].str[3:] == 'Strongly disagree', col] = 0\n",
    "    df_clean.loc[df[col].str[3:] == 'Somewhat disagree', col] = 1\n",
    "    df_clean.loc[df[col].str[3:] == 'Somewhat agree', col] = 2\n",
    "    df_clean.loc[df[col].str[3:] == 'Strongly agree', col] = 3\n",
    "\n",
    "#talks\n",
    "cols = ['sec5_q59', 'sec5_q61',  'sec5_q66'] #'sec5_q65',\n",
    "for col in cols:\n",
    "    df_clean[col] = np.nan\n",
    "    df_clean.loc[df[col].str[3:] == 'No', col] = 0\n",
    "    df_clean.loc[df[col].str[3:] == 'Yes', col] = 3\n",
    "    #df_clean.loc[df[col].str[3:] == 3, col] = 3\n",
    "    df_clean.loc[df[col].str[3:] == 'No one', col] = 3\n",
    "    df_clean.loc[df[col].str[3:] == 'Yes, many people', col] = 0\n",
    "    df_clean.loc[df[col].str[3:] == 'Yes, a few people', col] = 0\n",
    "    df_clean.loc[df[col].str[3:] == 'Yes, one person', col] = 0\n",
    "\n",
    "#concerns\n",
    "cols = ['sec3_q39', 'sec3_q40', 'sec3_q41', 'sec3_q42']\n",
    "for col in cols:\n",
    "    df_clean[col] = np.nan\n",
    "    df_clean.loc[df[col].str[3:] == 'Strongly disagree', col] = 3\n",
    "    df_clean.loc[df[col].str[3:] == 'Somewhat disagree', col] = 2\n",
    "    df_clean.loc[df[col].str[3:] == 'Somewhat agree', col] = 1\n",
    "    df_clean.loc[df[col].str[3:] == 'Strongly agree', col] = 0\n",
    "\n",
    "#feels others\n",
    "cols = ['sec5_q64']\n",
    "for col in cols:\n",
    "    df_clean[col] = np.nan\n",
    "    df_clean.loc[df[col].str[3:] == 'Strongly disagree', col] = 0\n",
    "    df_clean.loc[df[col].str[3:] == 'Disagree', col] = 1\n",
    "    df_clean.loc[df[col].str[3:] == 'Agree', col] = 2\n",
    "    df_clean.loc[df[col].str[3:] == 'Strongly agree', col] = 3\n",
    "\n",
    "#outcome\n",
    "df_clean['anydoses'] = np.nan\n",
    "df_clean.loc[df['AnyHPVdoses'].str[3:] == 'No', 'anydoses'] = 0\n",
    "df_clean.loc[df['AnyHPVdoses'].str[3:] == 'Yes', 'anydoses'] = 1\n",
    "\n",
    "# extra questions: 'sec5_q64', 'sec5_q63', 'sec6_q73', 'sec6_q74', 'sec3_q33', 'sec5_q60', 'sec5_q62', 'Correct_A_q83'\n",
    "extra_cols = ['sec5_q64', 'sec5_q63', 'sec6_q73', 'sec6_q74', 'sec3_q33', 'sec5_q60', 'sec5_q62', 'Correct_A_q83']\n",
    "for col in extra_cols:\n",
    "    df_clean[col] = np.nan\n",
    "    \n",
    "    df_clean.loc[df[col].str[3:] == 'Strongly disagree', col] = 3\n",
    "    df_clean.loc[df[col].str[3:] == 'Disagree', col] = 2\n",
    "    df_clean.loc[df[col].str[3:] == 'Somewhat disagree', col] = 2\n",
    "    df_clean.loc[df[col].str[3:] == 'Agree', col] = 1\n",
    "    df_clean.loc[df[col].str[3:] == 'Somewhat agree', col] = 1\n",
    "    df_clean.loc[df[col].str[3:] == 'Strongly agree', col] = 0\n",
    "    \n",
    "    df_clean.loc[df[col].str[3:] == 'Alot', col] = 3\n",
    "    df_clean.loc[df[col].str[3:] == 'Some', col] = 2\n",
    "    df_clean.loc[df[col].str[3:] == 'Not much', col] = 1\n",
    "    df_clean.loc[df[col].str[3:] == 'Not at all', col] = 0\n",
    "\n",
    "    df_clean.loc[df[col].str[3:] == 'Not at all comfortable', col] = 0\n",
    "    df_clean.loc[df[col].str[3:] == 'Somewhat comfortable', col] = 1\n",
    "    df_clean.loc[df[col].str[3:] == 'Very comfortable', col] = 2\n",
    "\n",
    "    df_clean.loc[df[col].str[3:] == 'No', col] = 0\n",
    "    df_clean.loc[df[col].str[3:] == 'Yes', col] = 1\n",
    "if col == 'Correct_A_q83':\n",
    "    df_clean[col] = df_clean[col].fillna(0)\n",
    "    \n",
    "df_clean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456534a2-496d-45af-8fea-2903baf4a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40234099-7500-4003-b4c1-d6d8d159569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3829e6-c31a-47e5-9053-5f66eb2d2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data by question\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb36a64-e1e6-4eb4-91bc-fede16b40e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many questions did each person skip?\n",
    "pd.DataFrame(df_clean.isna().sum(axis=1)).groupby(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5fec50-7d6d-4189-8e9f-05f1a5c492cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of observations with at least one missing question\n",
    "df_clean.id[df_clean.isna().sum(axis=1)>0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e25096-9cae-4c98-a231-50b3bc9db4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[df_clean.isna().sum(axis=1)>14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a8569-06ed-4368-8b13-cedfe520300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the 2 people who skipped 15 questions\n",
    "df_clean = df_clean[df_clean.isna().sum(axis=1)<=14].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca8d3fb-e31b-48a0-a1b6-df6c573d22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[df_clean.isna().sum(axis=1)>14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76fb76-bd80-4a1b-ad2a-62d95cfd3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f13fb-53e8-4c9e-9e73-2ee0b29d9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_clean.columns.drop('id'):\n",
    "    df_clean[col] = df_clean[col].astype('category')\n",
    "    \n",
    "df_clean[df_clean.columns.drop('id')].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3ca78-bdfb-4d36-8d69-03f38477b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "369/1345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c4c89-bb70-4a7c-8129-6da27b3af3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb427ab-b99c-46fe-9f7e-516da6f82b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "\n",
    "#for sec3_q28, it's almost always 0, so just impute 0\n",
    "df_clean['sec3_q28'] = df_clean['sec3_q28'].fillna(3.0)\n",
    "\n",
    "for col in df_clean.columns.drop('id'):\n",
    "    df_clean[col] = df_clean[col].astype('category')\n",
    "\n",
    "num_datasets = 20\n",
    "\n",
    "kernel = mf.ImputationKernel(\n",
    "  df_clean[df_clean.columns.drop('id')],\n",
    "  num_datasets=num_datasets,\n",
    "  random_state=1991,\n",
    "  mean_match_candidates=0  # Skip mean matching\n",
    ")\n",
    "\n",
    "kernel.mice(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124fce49-d22b-48ce-96d9-33361531cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.complete_data(dataset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018b0b8-2612-4123-a9f7-cc056a2e7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### average scores\n",
    "\n",
    "cols = ['motivationscore', \n",
    "       'confidence', 'sec3_q28', 'sec3_q29', 'sec3_q36', 'sec3_q37', 'sec3_q38', 'sec3_q45',\n",
    "       'talks', 'sec5_q59', 'sec5_q61',  'sec5_q66', #'sec5_q65',\n",
    "       'concerns', 'sec3_q39', 'sec3_q40', 'sec3_q41', 'sec3_q42',\n",
    "       'feelsothers',\n",
    "       'sec5_q64', 'sec5_q63', 'sec6_q73', 'sec6_q74', 'sec3_q33', 'sec5_q60', 'sec5_q62', 'Correct_A_q83']\n",
    "\n",
    "coefs = pd.DataFrame([], columns = cols)\n",
    "errs = pd.DataFrame([], columns = cols)\n",
    "\n",
    "\n",
    "for d in range(num_datasets):\n",
    "    df_imputed = kernel.complete_data(dataset=d).copy()\n",
    "\n",
    "    for col in df_imputed.columns:\n",
    "        df_imputed[col] = df_imputed[col].astype('int')\n",
    "\n",
    "    df_imputed['confidence'] = df_imputed['sec3_q28'] + df_imputed['sec3_q29'] + df_imputed['sec3_q36'] + df_imputed['sec3_q37'] + df_imputed['sec3_q38'] + df_imputed['sec3_q45']\n",
    "    df_imputed['talks'] = df_imputed['sec5_q59'] + df_imputed['sec5_q61']      + df_imputed['sec5_q66'] #+ df_imputed['sec5_q65']\n",
    "    df_imputed['concerns'] = df_imputed['sec3_q39'] + df_imputed['sec3_q40'] + df_imputed['sec3_q41'] + df_imputed['sec3_q42']\n",
    "    df_imputed['feelsothers'] = df_imputed['sec5_q64']\n",
    "    df_imputed['motivationscore'] = df_imputed['confidence'] + df_imputed['talks'] + df_imputed['concerns'] + df_imputed['feelsothers']\n",
    "    \n",
    "    cs = []\n",
    "    stderrs = []\n",
    "    for col in cols:\n",
    "        \n",
    "        cs = cs + [df_imputed[col].mean()]\n",
    "        stderrs = stderrs + [df_imputed[col].sem()]\n",
    "    \n",
    "    coefs.loc[d] = cs\n",
    "    errs.loc[d] = stderrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f1655-28b2-4b96-930f-443eed9455a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(round(coefs.mean(), 2).astype(str) + ' ± ' + round((((errs.mean())**2 + ((1 + 1/num_datasets) * (num_datasets) / (num_datasets - 1) * errs.std())**2)**0.5)*1.96,2).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3065-9408-418a-8138-a8ac7ce0e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# odds ratios\n",
    "\n",
    "cols = ['motivationscore', \n",
    "       'confidence', 'sec3_q28', 'sec3_q29', 'sec3_q36', 'sec3_q37', 'sec3_q38', 'sec3_q45',\n",
    "       'talks', 'sec5_q59', 'sec5_q61', 'sec5_q66', # 'sec5_q65',\n",
    "       'concerns', 'sec3_q39', 'sec3_q40', 'sec3_q41', 'sec3_q42',\n",
    "       'feelsothers',\n",
    "       'sec5_q64', 'sec5_q63', 'sec6_q73', 'sec6_q74', 'sec3_q33', 'sec5_q60', 'sec5_q62', 'Correct_A_q83']\n",
    "\n",
    "coefs = pd.DataFrame([], columns = cols)\n",
    "errs = pd.DataFrame([], columns = cols)\n",
    "\n",
    "\n",
    "for d in range(num_datasets):\n",
    "    df_imputed = kernel.complete_data(dataset=d).copy()\n",
    "\n",
    "    for col in df_imputed.columns:\n",
    "        df_imputed[col] = df_imputed[col].astype('int')\n",
    "    \n",
    "    df_imputed['const'] = 1\n",
    "    df_imputed['confidence'] = df_imputed['sec3_q28'] + df_imputed['sec3_q29'] + df_imputed['sec3_q36'] + df_imputed['sec3_q37'] + df_imputed['sec3_q38'] + df_imputed['sec3_q45']\n",
    "    df_imputed['talks'] = df_imputed['sec5_q59'] + df_imputed['sec5_q61'] + df_imputed['sec5_q66'] # + df_imputed['sec5_q65'] \n",
    "    df_imputed['concerns'] = df_imputed['sec3_q39'] + df_imputed['sec3_q40'] + df_imputed['sec3_q41'] + df_imputed['sec3_q42']\n",
    "    df_imputed['feelsothers'] = df_imputed['sec5_q64']\n",
    "    df_imputed['motivationscore'] = df_imputed['confidence'] + df_imputed['talks'] + df_imputed['concerns'] + df_imputed['feelsothers']\n",
    "    \n",
    "    cs = []\n",
    "    stderrs = []\n",
    "    for col in cols:\n",
    "\n",
    "        y = df_imputed['anydoses'] \n",
    "        X = df_imputed[['const', col]] \n",
    "    \n",
    "        model = sm.Logit(y, X)\n",
    "        res = model.fit(maxiter = 100)\n",
    "\n",
    "        vals = res.summary2().tables[1]\n",
    "        cs = cs + [vals['Coef.'].iloc[1]]\n",
    "        stderrs = stderrs + [vals['Std.Err.'].iloc[1]]\n",
    "    \n",
    "    coefs.loc[d] = cs\n",
    "    errs.loc[d] = stderrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573453a0-9581-41fd-a3b5-14896a884230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "coef_mi = coefs.mean()\n",
    "stderr_mi = (errs.mean()**2 + (1 + 1/num_datasets) * (num_datasets) / (num_datasets - 1) * errs.std()**2)**0.5\n",
    "df_ans= pd.DataFrame(np.round(np.exp(coef_mi),2).astype(str) + ' [' + np.round(np.exp(coef_mi - 1.96 * stderr_mi),2).astype(str) + ', ' + np.round(np.exp(coef_mi + 1.96 * stderr_mi),2).astype(str) + ']', columns = ['OR'])\n",
    "df_ans['p'] = np.round((1 - st.norm.cdf(np.abs(coef_mi/stderr_mi))) * 2,4)\n",
    "df_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60638f1e-0602-45b8-8306-4e7d9bd63161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e1f1a-a3af-4c91-a9b1-d344540f972c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e198cc8-4409-448c-a0e9-02f1584e7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541dbec-e5cc-4fbc-820e-dc7c9b57630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b5a45-273d-4ccb-9f8c-b1883e36c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_excel('parent_vax_followup2024.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a536c-e4ca-4cdf-8712-f28c3d11e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['caseid2'] = df_clean.caseid.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92870395-4044-4a2f-a1c5-c9071e7ed0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "       'sec3_q28', 'sec3_q29', 'sec3_q36', 'sec3_q37', 'sec3_q38', 'sec3_q45',\n",
    "       'sec5_q59', 'sec5_q61',  'sec5_q66', #'sec5_q65',\n",
    "       'sec3_q39', 'sec3_q40', 'sec3_q41', 'sec3_q42',\n",
    "       \n",
    "       'sec5_q64', 'anydoses', 'vax_any']\n",
    "\n",
    "df_two = pd.merge(df_clean, df_new, left_on = 'caseid2', right_on = 'caseid')\n",
    "df_two = df_two[['caseid_x'] + cols].copy()\n",
    "df_two[df_two.anydoses==0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad0de9-be19-479c-a0ec-d086144e7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_2 = df_two[df_two.anydoses==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b51b40-5f52-46c4-b8b9-e74b2db5d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_clean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81045f67-9fda-4df5-a2a8-e2084419932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_2[['caseid_x', 'anydoses', 'vax_any']].rename(columns={'caseid_x':'caseid', 'anydoses':'anydoses_2022', 'vax_any':'anydoses_2024'}).to_csv('Kenya2024_caseids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1899b5d-2108-427f-92bc-29eeb0df01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "\n",
    "#for sec3_q28, it's almost always 0, so just impute 0\n",
    "df_clean_2['sec3_q28'] = df_clean_2['sec3_q28'].fillna(3.0)\n",
    "\n",
    "for col in df_clean_2.columns.drop('caseid_x'):\n",
    "    df_clean[col] = df_clean_2[col].astype('category')\n",
    "\n",
    "num_datasets = 20\n",
    "\n",
    "kernel = mf.ImputationKernel(\n",
    "  df_clean[df_clean_2.columns.drop('caseid_x')],\n",
    "  num_datasets=num_datasets,\n",
    "  random_state=1991,\n",
    "  mean_match_candidates=0  # Skip mean matching\n",
    ")\n",
    "\n",
    "kernel.mice(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f35fd1-afd8-4ace-a5b8-c887fec57b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.complete_data(dataset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046519d7-b706-4b9d-8bbe-af2f01d345a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### average scores\n",
    "\n",
    "cols = ['motivationscore', \n",
    "       'confidence', 'sec3_q28', 'sec3_q29', 'sec3_q36', 'sec3_q37', 'sec3_q38', 'sec3_q45',\n",
    "       'talks', 'sec5_q59', 'sec5_q61',  'sec5_q66', #'sec5_q65',\n",
    "       'concerns', 'sec3_q39', 'sec3_q40', 'sec3_q41', 'sec3_q42',\n",
    "       'feelsothers']\n",
    "       #'sec5_q64', 'sec5_q63', 'sec6_q73', 'sec6_q74', 'sec3_q33', 'sec5_q60', 'sec5_q62', 'Correct_A_q83']\n",
    "\n",
    "coefs = pd.DataFrame([], columns = cols)\n",
    "errs = pd.DataFrame([], columns = cols)\n",
    "\n",
    "\n",
    "for d in range(num_datasets):\n",
    "    df_imputed = kernel.complete_data(dataset=d).copy()\n",
    "\n",
    "    for col in df_imputed.columns:\n",
    "        df_imputed[col] = df_imputed[col].astype('int')\n",
    "\n",
    "    df_imputed['confidence'] = df_imputed['sec3_q28'] + df_imputed['sec3_q29'] + df_imputed['sec3_q36'] + df_imputed['sec3_q37'] + df_imputed['sec3_q38'] + df_imputed['sec3_q45']\n",
    "    df_imputed['talks'] = df_imputed['sec5_q59'] + df_imputed['sec5_q61']      + df_imputed['sec5_q66'] #+ df_imputed['sec5_q65']\n",
    "    df_imputed['concerns'] = df_imputed['sec3_q39'] + df_imputed['sec3_q40'] + df_imputed['sec3_q41'] + df_imputed['sec3_q42']\n",
    "    df_imputed['feelsothers'] = df_imputed['sec5_q64']\n",
    "    df_imputed['motivationscore'] = df_imputed['confidence'] + df_imputed['talks'] + df_imputed['concerns'] + df_imputed['feelsothers']\n",
    "    \n",
    "    cs = []\n",
    "    stderrs = []\n",
    "    for col in cols:\n",
    "        \n",
    "        cs = cs + [df_imputed[col].mean()]\n",
    "        stderrs = stderrs + [df_imputed[col].sem()]\n",
    "    \n",
    "    coefs.loc[d] = cs\n",
    "    errs.loc[d] = stderrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6a61e-9a46-4ec8-9905-eccc70c6f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(round(coefs.mean(), 2).astype(str) + ' ± ' + round((((errs.mean())**2 + ((1 + 1/num_datasets) * (num_datasets) / (num_datasets - 1) * errs.std())**2)**0.5)*1.96,2).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5c597-b25a-4f9e-afe6-efc16880dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# odds ratios\n",
    "\n",
    "cols = ['motivationscore', \n",
    "       'confidence', 'sec3_q28', 'sec3_q29', 'sec3_q36', 'sec3_q37', 'sec3_q38', 'sec3_q45',\n",
    "       'talks', 'sec5_q59', 'sec5_q61', 'sec5_q66', # 'sec5_q65',\n",
    "       'concerns', 'sec3_q39', 'sec3_q40', 'sec3_q41', 'sec3_q42',\n",
    "       'feelsothers']\n",
    "       #'sec5_q64', 'sec5_q63', 'sec6_q73', 'sec6_q74', 'sec3_q33', 'sec5_q60', 'sec5_q62', 'Correct_A_q83']\n",
    "\n",
    "coefs = pd.DataFrame([], columns = cols)\n",
    "errs = pd.DataFrame([], columns = cols)\n",
    "\n",
    "\n",
    "for d in range(num_datasets):\n",
    "    df_imputed = kernel.complete_data(dataset=d).copy()\n",
    "\n",
    "    for col in df_imputed.columns:\n",
    "        df_imputed[col] = df_imputed[col].astype('int')\n",
    "    \n",
    "    df_imputed['const'] = 1\n",
    "    df_imputed['confidence'] = df_imputed['sec3_q28'] + df_imputed['sec3_q29'] + df_imputed['sec3_q36'] + df_imputed['sec3_q37'] + df_imputed['sec3_q38'] + df_imputed['sec3_q45']\n",
    "    df_imputed['talks'] = df_imputed['sec5_q59'] + df_imputed['sec5_q61'] + df_imputed['sec5_q66'] # + df_imputed['sec5_q65'] \n",
    "    df_imputed['concerns'] = df_imputed['sec3_q39'] + df_imputed['sec3_q40'] + df_imputed['sec3_q41'] + df_imputed['sec3_q42']\n",
    "    df_imputed['feelsothers'] = df_imputed['sec5_q64']\n",
    "    df_imputed['motivationscore'] = df_imputed['confidence'] + df_imputed['talks'] + df_imputed['concerns'] + df_imputed['feelsothers']\n",
    "    \n",
    "    cs = []\n",
    "    stderrs = []\n",
    "    for col in cols:\n",
    "\n",
    "        y = df_imputed['vax_any'] \n",
    "        X = df_imputed[['const', col]] \n",
    "    \n",
    "        model = sm.Logit(y, X)\n",
    "        res = model.fit(maxiter = 100)\n",
    "\n",
    "        vals = res.summary2().tables[1]\n",
    "        cs = cs + [vals['Coef.'].iloc[1]]\n",
    "        stderrs = stderrs + [vals['Std.Err.'].iloc[1]]\n",
    "    \n",
    "    coefs.loc[d] = cs\n",
    "    errs.loc[d] = stderrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e13f2-c779-49ab-9815-f31dcd318c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "coef_mi = coefs.mean()\n",
    "stderr_mi = (errs.mean()**2 + (1 + 1/num_datasets) * (num_datasets) / (num_datasets - 1) * errs.std()**2)**0.5\n",
    "df_ans= pd.DataFrame(np.round(np.exp(coef_mi),2).astype(str) + ' [' + np.round(np.exp(coef_mi - 1.96 * stderr_mi),2).astype(str) + ', ' + np.round(np.exp(coef_mi + 1.96 * stderr_mi),2).astype(str) + ']', columns = ['OR'])\n",
    "df_ans['p'] = np.round((1 - st.norm.cdf(np.abs(coef_mi/stderr_mi))) * 2,4)\n",
    "df_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b52ed3f-6d22-4c09-9b84-c6cbd2070972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6a4b4-41c8-4c38-a5f8-f694ff785ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_clean_2, df, left_on='caseid_x', right_on='caseid').groupby('vax_any').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e91f00-9bdf-43f5-b478-792c64acd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "111+1+2+15+30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82548b09-abd2-4d98-89a1-182be6aa58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf513d2d-02d8-4efc-99db-d92f0899be14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e0d9e-337b-4c03-881a-47a66ca427a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
